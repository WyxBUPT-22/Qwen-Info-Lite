{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.999170124481328,
  "eval_steps": 500,
  "global_step": 2709,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.05532503457814661,
      "grad_norm": 0.19618026912212372,
      "learning_rate": 4.9e-05,
      "loss": 0.6847,
      "step": 50
    },
    {
      "epoch": 0.11065006915629322,
      "grad_norm": 0.25641778111457825,
      "learning_rate": 9.900000000000001e-05,
      "loss": 0.6394,
      "step": 100
    },
    {
      "epoch": 0.16597510373443983,
      "grad_norm": 0.281869113445282,
      "learning_rate": 9.99129922858415e-05,
      "loss": 0.5916,
      "step": 150
    },
    {
      "epoch": 0.22130013831258644,
      "grad_norm": 0.2990020513534546,
      "learning_rate": 9.964514770852713e-05,
      "loss": 0.588,
      "step": 200
    },
    {
      "epoch": 0.2766251728907331,
      "grad_norm": 0.31168049573898315,
      "learning_rate": 9.919740062608017e-05,
      "loss": 0.5808,
      "step": 250
    },
    {
      "epoch": 0.33195020746887965,
      "grad_norm": 0.3118516802787781,
      "learning_rate": 9.857137357011778e-05,
      "loss": 0.5543,
      "step": 300
    },
    {
      "epoch": 0.3872752420470263,
      "grad_norm": 0.29144930839538574,
      "learning_rate": 9.776933511754727e-05,
      "loss": 0.5415,
      "step": 350
    },
    {
      "epoch": 0.4426002766251729,
      "grad_norm": 0.3252294659614563,
      "learning_rate": 9.679419166976914e-05,
      "loss": 0.5417,
      "step": 400
    },
    {
      "epoch": 0.4979253112033195,
      "grad_norm": 0.32237708568573,
      "learning_rate": 9.56494769205524e-05,
      "loss": 0.5374,
      "step": 450
    },
    {
      "epoch": 0.5532503457814661,
      "grad_norm": 0.3590392470359802,
      "learning_rate": 9.43393390507476e-05,
      "loss": 0.5405,
      "step": 500
    },
    {
      "epoch": 0.6085753803596127,
      "grad_norm": 0.3133281469345093,
      "learning_rate": 9.286852569624112e-05,
      "loss": 0.5459,
      "step": 550
    },
    {
      "epoch": 0.6639004149377593,
      "grad_norm": 0.3215026557445526,
      "learning_rate": 9.124236674362354e-05,
      "loss": 0.5364,
      "step": 600
    },
    {
      "epoch": 0.719225449515906,
      "grad_norm": 0.29254916310310364,
      "learning_rate": 8.946675501591631e-05,
      "loss": 0.5188,
      "step": 650
    },
    {
      "epoch": 0.7745504840940526,
      "grad_norm": 0.3162423074245453,
      "learning_rate": 8.754812491834734e-05,
      "loss": 0.531,
      "step": 700
    },
    {
      "epoch": 0.8298755186721992,
      "grad_norm": 0.33073127269744873,
      "learning_rate": 8.549342912155833e-05,
      "loss": 0.5263,
      "step": 750
    },
    {
      "epoch": 0.8852005532503457,
      "grad_norm": 0.3485493063926697,
      "learning_rate": 8.33101133667383e-05,
      "loss": 0.5296,
      "step": 800
    },
    {
      "epoch": 0.9405255878284924,
      "grad_norm": 0.3361491560935974,
      "learning_rate": 8.100608948398381e-05,
      "loss": 0.5169,
      "step": 850
    },
    {
      "epoch": 0.995850622406639,
      "grad_norm": 0.3398491442203522,
      "learning_rate": 7.858970672166096e-05,
      "loss": 0.5133,
      "step": 900
    },
    {
      "epoch": 1.0520055325034579,
      "grad_norm": 0.3245599865913391,
      "learning_rate": 7.606972149066525e-05,
      "loss": 0.5268,
      "step": 950
    },
    {
      "epoch": 1.1073305670816045,
      "grad_norm": 0.3740355968475342,
      "learning_rate": 7.345526563321845e-05,
      "loss": 0.5017,
      "step": 1000
    },
    {
      "epoch": 1.1626556016597511,
      "grad_norm": 0.35817816853523254,
      "learning_rate": 7.07558133311898e-05,
      "loss": 0.497,
      "step": 1050
    },
    {
      "epoch": 1.2179806362378978,
      "grad_norm": 0.34062981605529785,
      "learning_rate": 6.798114677385731e-05,
      "loss": 0.5046,
      "step": 1100
    },
    {
      "epoch": 1.2733056708160442,
      "grad_norm": 0.3496808707714081,
      "learning_rate": 6.51413207095219e-05,
      "loss": 0.5031,
      "step": 1150
    },
    {
      "epoch": 1.3286307053941908,
      "grad_norm": 0.417468786239624,
      "learning_rate": 6.224662600943078e-05,
      "loss": 0.5097,
      "step": 1200
    },
    {
      "epoch": 1.3839557399723375,
      "grad_norm": 0.3815685510635376,
      "learning_rate": 5.930755237604583e-05,
      "loss": 0.4931,
      "step": 1250
    },
    {
      "epoch": 1.439280774550484,
      "grad_norm": 0.36363157629966736,
      "learning_rate": 5.633475033079402e-05,
      "loss": 0.4959,
      "step": 1300
    },
    {
      "epoch": 1.4946058091286307,
      "grad_norm": 0.3500247895717621,
      "learning_rate": 5.333899261904707e-05,
      "loss": 0.4973,
      "step": 1350
    },
    {
      "epoch": 1.5499308437067774,
      "grad_norm": 0.36866506934165955,
      "learning_rate": 5.033113517218978e-05,
      "loss": 0.4866,
      "step": 1400
    },
    {
      "epoch": 1.605255878284924,
      "grad_norm": 0.32306233048439026,
      "learning_rate": 4.732207776824176e-05,
      "loss": 0.5013,
      "step": 1450
    },
    {
      "epoch": 1.6605809128630704,
      "grad_norm": 0.3751160502433777,
      "learning_rate": 4.432272453358883e-05,
      "loss": 0.4994,
      "step": 1500
    },
    {
      "epoch": 1.7159059474412173,
      "grad_norm": 0.4132181406021118,
      "learning_rate": 4.1343944428957226e-05,
      "loss": 0.4843,
      "step": 1550
    },
    {
      "epoch": 1.7712309820193637,
      "grad_norm": 0.37624987959861755,
      "learning_rate": 3.83965318628198e-05,
      "loss": 0.4955,
      "step": 1600
    },
    {
      "epoch": 1.8265560165975103,
      "grad_norm": 0.4134129285812378,
      "learning_rate": 3.54911675749625e-05,
      "loss": 0.4844,
      "step": 1650
    },
    {
      "epoch": 1.881881051175657,
      "grad_norm": 0.36309686303138733,
      "learning_rate": 3.263837993195956e-05,
      "loss": 0.4965,
      "step": 1700
    },
    {
      "epoch": 1.9372060857538036,
      "grad_norm": 0.35975825786590576,
      "learning_rate": 2.9848506774814112e-05,
      "loss": 0.4823,
      "step": 1750
    },
    {
      "epoch": 1.9925311203319502,
      "grad_norm": 0.3862345218658447,
      "learning_rate": 2.7131657957019168e-05,
      "loss": 0.5035,
      "step": 1800
    },
    {
      "epoch": 2.048686030428769,
      "grad_norm": 0.34673595428466797,
      "learning_rate": 2.449767870879252e-05,
      "loss": 0.4892,
      "step": 1850
    },
    {
      "epoch": 2.1040110650069157,
      "grad_norm": 0.3579205572605133,
      "learning_rate": 2.1956113960245135e-05,
      "loss": 0.4769,
      "step": 1900
    },
    {
      "epoch": 2.159336099585062,
      "grad_norm": 0.3921021521091461,
      "learning_rate": 1.9516173752767204e-05,
      "loss": 0.4783,
      "step": 1950
    },
    {
      "epoch": 2.214661134163209,
      "grad_norm": 0.33366504311561584,
      "learning_rate": 1.7186699863973687e-05,
      "loss": 0.4812,
      "step": 2000
    },
    {
      "epoch": 2.2699861687413554,
      "grad_norm": 0.36977675557136536,
      "learning_rate": 1.4976133767152039e-05,
      "loss": 0.4786,
      "step": 2050
    },
    {
      "epoch": 2.3253112033195023,
      "grad_norm": 0.38651952147483826,
      "learning_rate": 1.2892486041320296e-05,
      "loss": 0.4807,
      "step": 2100
    },
    {
      "epoch": 2.3806362378976487,
      "grad_norm": 0.3860267102718353,
      "learning_rate": 1.09433073427458e-05,
      "loss": 0.4759,
      "step": 2150
    },
    {
      "epoch": 2.4359612724757955,
      "grad_norm": 0.4096086323261261,
      "learning_rate": 9.135661043117698e-06,
      "loss": 0.4718,
      "step": 2200
    },
    {
      "epoch": 2.491286307053942,
      "grad_norm": 0.4057832658290863,
      "learning_rate": 7.476097633525342e-06,
      "loss": 0.477,
      "step": 2250
    },
    {
      "epoch": 2.5466113416320884,
      "grad_norm": 0.40518617630004883,
      "learning_rate": 5.9706309869974885e-06,
      "loss": 0.4745,
      "step": 2300
    },
    {
      "epoch": 2.601936376210235,
      "grad_norm": 0.39961129426956177,
      "learning_rate": 4.624716565620673e-06,
      "loss": 0.4717,
      "step": 2350
    },
    {
      "epoch": 2.6572614107883816,
      "grad_norm": 0.3892296552658081,
      "learning_rate": 3.443231651209433e-06,
      "loss": 0.4748,
      "step": 2400
    },
    {
      "epoch": 2.7125864453665285,
      "grad_norm": 0.4118613302707672,
      "learning_rate": 2.430457671167863e-06,
      "loss": 0.4801,
      "step": 2450
    },
    {
      "epoch": 2.767911479944675,
      "grad_norm": 0.4218527376651764,
      "learning_rate": 1.5900646835892985e-06,
      "loss": 0.4633,
      "step": 2500
    },
    {
      "epoch": 2.8232365145228213,
      "grad_norm": 0.37575000524520874,
      "learning_rate": 9.250980778166996e-07,
      "loss": 0.4835,
      "step": 2550
    },
    {
      "epoch": 2.878561549100968,
      "grad_norm": 0.4346417784690857,
      "learning_rate": 4.379675386577409e-07,
      "loss": 0.4734,
      "step": 2600
    },
    {
      "epoch": 2.933886583679115,
      "grad_norm": 0.42957252264022827,
      "learning_rate": 1.3043831424575104e-07,
      "loss": 0.48,
      "step": 2650
    },
    {
      "epoch": 2.9892116182572614,
      "grad_norm": 0.38818156719207764,
      "learning_rate": 3.624819189745887e-09,
      "loss": 0.4871,
      "step": 2700
    }
  ],
  "logging_steps": 50,
  "max_steps": 2709,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.819645724446556e+17,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
